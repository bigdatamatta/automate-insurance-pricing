<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>automate_insurance_pricing.exploration.checks_functions API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>automate_insurance_pricing.exploration.checks_functions</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np

from scipy import stats

from copy import deepcopy
from datetime import date, timedelta, datetime



def check_row_consistency(x, df, policy_id_column_name, main_column_contract_date, claim_occurrence_date, unknown_row_name, number_of_days):
    &#34;&#34;&#34;Checks if the line should be kept in the data or not  
        Arguments --&gt; the row, the dataframe, the policy, contract start and claim occurrence dates columns,
            The value associated to rows for which we do not have enough information, and the number of days for each contract (usually 365)  
        Returns --&gt; a boolean with 1 if the row is consistent and 0 otherwise
    &#34;&#34;&#34;

    row = df.loc[x]
    policy_id = row[policy_id_column_name]
    year_name = main_column_contract_date
    result = 0
    effective_date = row[year_name]
    effective_dates = df[df[policy_id_column_name]==policy_id][year_name]

    # For policy_id with UNKNOWN value, we keep all claims because we cannot link them to a policy but we group them in an UNKNOWN block so that we don&#39;t understimate the total cost
    if policy_id != unknown_row_name:
        # Contract started after the claim occurrence
        if effective_date &gt; row[claim_occurrence_date]:
            result = 1
        # The claim did not occurr during the yearly contract cover;
        # By prudency, also checks if there is a contract amendment. if not we assume it is a date mistake and we do not set the cost to 0
        elif effective_date + timedelta(number_of_days) &lt;= row[claim_occurrence_date] and effective_date &lt; effective_dates.max():
            result = 1

    return result


def add_back_lines(df, df_removed, main_column_contract_date, claim_id_column_name, claim_occurrence_date_column_name):
    &#34;&#34;&#34;
        Adds backs to the data some of the claims that were removed if they were removed only due to an inconsistent occurrence date   
        Arguments --&gt; the dataframe with only the correct claims, the dataframe storing the removed ones   
            the contract start and occurrence date column name   
        Returns --&gt; a new df that now have back the claims that were removed
    &#34;&#34;&#34;

    year_name = main_column_contract_date

    # To find these claims we look at the claims that were in the original claims data but are not in the newly created
    wrongly_removed = df_removed[~df_removed[claim_id_column_name].isin(df[claim_id_column_name])].drop_duplicates(subset=claim_id_column_name, keep=&#39;last&#39;)

    # We add them back in our claims because we prefer being wrong in the occurrence dates rather than reducing the total costs
    new_df = pd.concat((df, wrongly_removed), sort=False).reset_index(drop=True)

    # Changes the dates so that it is now consistent. It means there might be cost overestimation for some occurrence year, but it won&#39;t have any impact overall
    new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, claim_occurrence_date_column_name] = new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, year_name] + timedelta(days=1)

    return new_df



def find_wrong_lines(df, main_column_contract_date, lines_ro_remove_name, number_of_days=None, remove=False):
    &#34;&#34;&#34;
        Finds the lines that seem to be wrong either because they are duplicates or because a date inconsistency has been detected   
        Arguments --&gt; the df on which we are doing the check, the constract start date columns,   
            the name that will be given to the rows flagged as wrong, the number of days that should serve to check dates consistency (usually 365 for yearly contracts)   
            i.e. for a given policy and its effective date, a claim occurring beyond that number of days should not be associate to it (usually 365 for yearly contracts),   
            and a remove argument that if set to True means all the lines considered wrong are removed from the df   
        Returns --&gt; 2 dataframes, one which will be either with a flag for wrong lines or with all these lines removed,   
                    and a new one which contains only the removed lines
    &#34;&#34;&#34;

    new_df = deepcopy(df)
    number_of_days = 365 if number_of_days is None else number_of_days

    new_df[lines_ro_remove_name] = new_df.index.to_frame()[0].apply(lambda x: check_row_consistency(x, new_df, main_column_contract_date, number_of_days))

    if remove == True:
        df_removed_lines = new_df[new_df[lines_ro_remove_name] == 1]
        line_to_remove_index = df_removed_lines.index
        new_df = new_df.drop(labels=line_to_remove_index).drop(columns=lines_ro_remove_name)
    else:
        df_removed_lines = pd.DataFrame()
        print(&#39;You just agged the lines that are incorrect and should most likely be removed.  \n \
Retreat these lines, then run again this function with the remove argument set to True to delete remaining unnecessary lines&#39;)

    return new_df.reset_index(drop=True), df_removed_lines



def create_unknown_policy(df_portfolio, df_claims, features_analysis, policy_id_column_name=&#39;policy_id&#39;, unknown_row_name=&#39;UNKNOWN&#39;):
    &#34;&#34;&#34; Finds policies that are in the claims data but not in the porfolio, and generates a new policy on the portfolio data to represent these unknown policies   
        Arguments -&gt; the portfolio and claims dataframes, the features for which we will impute a value for the identified policies,   
            (since the policies are added in the porfolio, a value has to be assumed for each of their features)   
            the policy id column name to use and the policy id name we will give to these policies found in the claims but not in the porfolio   
        Returns --&gt; a new portfolio and claims dataframe with the new policy name given to the identified policies  
    &#34;&#34;&#34;

    new_df_portfolio, new_df_claims = deepcopy(df_portfolio), deepcopy(df_claims)

    # Finds the claimants that do not exist in the portfolio data
    mask = ~new_df_claims[policy_id_column_name].isin(new_df_portfolio[policy_id_column_name])
    df_not_existing_policies = new_df_claims[mask]

    new_df_claims.loc[df_not_existing_policies.index, policy_id_column_name] = unknown_row_name

    # Reseting df index just in case to be sure we take the last row using shape
    new_df_portfolio = new_df_portfolio.reset_index(drop=True)
    # Gets the last row values and affect them to a new row
    new_row_df = new_df_portfolio.loc[new_df_portfolio.shape[0]-1]
    new_df_portfolio.loc[new_df_portfolio.shape[0]] = new_row_df
    new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, [policy_id_column_name]] = unknown_row_name

    # For each feature, derives the mode or the average and assigns it to the new row (a simple fillna might be faster)
    for feature in features_analysis:
        if new_df_portfolio[feature].dtype in [&#39;object&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mode()[0]
        elif new_df_portfolio[feature].dtype in [&#39;float64&#39;, &#39;int64&#39;, &#39;int32&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mean()

    print(&#39;There are {} policies in the claims that cannot be found in the porfolio data&#39;.format(df_not_existing_policies.shape[0]))

    return new_df_portfolio, new_df_claims



def find_outliers(df, columns=None, method=&#39;interquartile&#39;, z_score_threshold=3, interquartile_lower_bound=0.25, interquartile_upper_bound=0.75):
    &#34;&#34;&#34;
        Finds outliers for the specified features   
        Arguments --&gt; the dataframe on which to find outliers, the features as a name or list of names and the method to use to find outliers (either interquartile or z-score)   
            the z-score and the interquartile thresholds to use   
        Returns --&gt; the initial dataframe, the dataframe with only outliers and the new df without the outliers
    &#34;&#34;&#34;

    new_df = deepcopy(df)

    if method == &#39;interquartile&#39;:
        new_columns = [columns] if isinstance(columns, str) == True else columns

        for column in new_columns:
            quantile_25 = df[column].quantile(interquartile_lower_bound)
            quantile_75 = df[column].quantile(interquartile_upper_bound)

            interquartile_range = quantile_75 - quantile_25
            lower_bound = quantile_25 - 1.5 * interquartile_range
            upper_bound = quantile_75 + 1.5 * interquartile_range

            new_df = new_df[(new_df[column] &gt;= lower_bound) &amp; (new_df[column] &lt;= upper_bound)]

    else:

        z_score = np.abs(stats.zscore(df[columns]))
        new_df = new_df[z_score&lt;3] if isinstance(columns, str) == True else new_df[(z_score&lt;3).all(axis=1)]

    df_outliers = df[~df.index.isin(new_df.index)]
    proportion_outliers = len(df_outliers) / len(df)

    if proportion_outliers &gt; 0.05:
        print(&#34;Outliers represent a high proportion of the data: {}%. We should not remove them all&#34;.format(proportion_outliers))
        return deepcopy(df), df_outliers, df
    else:
        print(&#39;{} rows have been removed&#39;.format(df_outliers.shape[0]))
        return deepcopy(df), df_outliers, new_df
    
    

def perform_sense_check(df, new_cell_name=None, **kwargs):
    &#34;&#34;&#34;
       Finds data which is inconsistent on the columns specified in the kwargs   
       Arguments --&gt; the dataframe, the name of the new column created to flag if the row is consistent or not,   
            if not specified, then the function creates a new df composed of the rows for which the comparison check is true   
            kwargs --&gt; tuples like (column1, column2, comparison_to_do, strict_comparison)   
            or (column1, integer, comparison_to_do) ; comparison_to_do must be 0 for ==, 1 for &lt;=, 2 for &gt;=   
            if strict_comparison is True, then the comparison must be strict (&gt; or &lt;)   
       Returns --&gt; either a new dataframe containing all rows that meet the comparison check or the current dataframe with a new cell that flags them
   &#34;&#34;&#34;

    # Defines if the second argument to compare with is a integer/float or a pandas serie   
    # Returns --&gt; the right element that must be used for the comparison
    def get_compare():

        if isinstance(value[1], str) == True:
            # The second element of the tuple being a column name, we get the pandas serie
            compare = df[value[1]]            
        else:
            # The second element of the tuple being a number, we just retrieve the number itself
            compare = value[1]
            

        return compare

    #Returns the concatenated dataframe validating the check or updates the df column used to flag if the comparison is true or not
    def create_new_cell_or_df(): 

        # Cell name not being defined, it means the function must create a dataframe
        if new_cell_name is None:
            # As several checks can be done, a concatenation between the previous check and the new one is made
            return pd.concat((df_check, df[mask]), axis=0).drop_duplicates(keep=&#39;first&#39;)
        else:
            # The original df is modified with a new column that will have true/false value. If there are several checks performed, the row will be flagged true if it validates at least 1 check
            df[new_cell_name] = df[new_cell_name] | mask if new_cell_name in df.columns else mask

         
    df_check = pd.DataFrame()
    
    # Loops trough the kwargs
    for value in kwargs.values():

        # These lines checks the comparison operation to do
        if value[2] == 0:
            compare = get_compare()           
            mask = df[value[0]] == compare

        elif value[2] == 1:
            compare = get_compare()
            mask = df[value[0]] &lt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &lt; compare
            
        else:
            compare = get_compare()
            mask = df[value[0]] &gt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &gt; compare
        
        df_check = create_new_cell_or_df()
            
    if new_cell_name is None:
        print(&#39;There are {} rows concerned&#39;.format(df_check.shape[0]))
        return df_check
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="automate_insurance_pricing.exploration.checks_functions.add_back_lines"><code class="name flex">
<span>def <span class="ident">add_back_lines</span></span>(<span>df, df_removed, main_column_contract_date, claim_id_column_name, claim_occurrence_date_column_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds backs to the data some of the claims that were removed if they were removed only due to an inconsistent occurrence date <br>
Arguments &ndash;&gt; the dataframe with only the correct claims, the dataframe storing the removed ones <br>
the contract start and occurrence date column name <br>
Returns &ndash;&gt; a new df that now have back the claims that were removed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_back_lines(df, df_removed, main_column_contract_date, claim_id_column_name, claim_occurrence_date_column_name):
    &#34;&#34;&#34;
        Adds backs to the data some of the claims that were removed if they were removed only due to an inconsistent occurrence date   
        Arguments --&gt; the dataframe with only the correct claims, the dataframe storing the removed ones   
            the contract start and occurrence date column name   
        Returns --&gt; a new df that now have back the claims that were removed
    &#34;&#34;&#34;

    year_name = main_column_contract_date

    # To find these claims we look at the claims that were in the original claims data but are not in the newly created
    wrongly_removed = df_removed[~df_removed[claim_id_column_name].isin(df[claim_id_column_name])].drop_duplicates(subset=claim_id_column_name, keep=&#39;last&#39;)

    # We add them back in our claims because we prefer being wrong in the occurrence dates rather than reducing the total costs
    new_df = pd.concat((df, wrongly_removed), sort=False).reset_index(drop=True)

    # Changes the dates so that it is now consistent. It means there might be cost overestimation for some occurrence year, but it won&#39;t have any impact overall
    new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, claim_occurrence_date_column_name] = new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, year_name] + timedelta(days=1)

    return new_df</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.check_row_consistency"><code class="name flex">
<span>def <span class="ident">check_row_consistency</span></span>(<span>x, df, policy_id_column_name, main_column_contract_date, claim_occurrence_date, unknown_row_name, number_of_days)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if the line should be kept in the data or not<br>
Arguments &ndash;&gt; the row, the dataframe, the policy, contract start and claim occurrence dates columns,
The value associated to rows for which we do not have enough information, and the number of days for each contract (usually 365)<br>
Returns &ndash;&gt; a boolean with 1 if the row is consistent and 0 otherwise</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_row_consistency(x, df, policy_id_column_name, main_column_contract_date, claim_occurrence_date, unknown_row_name, number_of_days):
    &#34;&#34;&#34;Checks if the line should be kept in the data or not  
        Arguments --&gt; the row, the dataframe, the policy, contract start and claim occurrence dates columns,
            The value associated to rows for which we do not have enough information, and the number of days for each contract (usually 365)  
        Returns --&gt; a boolean with 1 if the row is consistent and 0 otherwise
    &#34;&#34;&#34;

    row = df.loc[x]
    policy_id = row[policy_id_column_name]
    year_name = main_column_contract_date
    result = 0
    effective_date = row[year_name]
    effective_dates = df[df[policy_id_column_name]==policy_id][year_name]

    # For policy_id with UNKNOWN value, we keep all claims because we cannot link them to a policy but we group them in an UNKNOWN block so that we don&#39;t understimate the total cost
    if policy_id != unknown_row_name:
        # Contract started after the claim occurrence
        if effective_date &gt; row[claim_occurrence_date]:
            result = 1
        # The claim did not occurr during the yearly contract cover;
        # By prudency, also checks if there is a contract amendment. if not we assume it is a date mistake and we do not set the cost to 0
        elif effective_date + timedelta(number_of_days) &lt;= row[claim_occurrence_date] and effective_date &lt; effective_dates.max():
            result = 1

    return result</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.create_unknown_policy"><code class="name flex">
<span>def <span class="ident">create_unknown_policy</span></span>(<span>df_portfolio, df_claims, features_analysis, policy_id_column_name='policy_id', unknown_row_name='UNKNOWN')</span>
</code></dt>
<dd>
<div class="desc"><p>Finds policies that are in the claims data but not in the porfolio, and generates a new policy on the portfolio data to represent these unknown policies <br>
Arguments -&gt; the portfolio and claims dataframes, the features for which we will impute a value for the identified policies, <br>
(since the policies are added in the porfolio, a value has to be assumed for each of their features) <br>
the policy id column name to use and the policy id name we will give to these policies found in the claims but not in the porfolio <br>
Returns &ndash;&gt; a new portfolio and claims dataframe with the new policy name given to the identified policies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_unknown_policy(df_portfolio, df_claims, features_analysis, policy_id_column_name=&#39;policy_id&#39;, unknown_row_name=&#39;UNKNOWN&#39;):
    &#34;&#34;&#34; Finds policies that are in the claims data but not in the porfolio, and generates a new policy on the portfolio data to represent these unknown policies   
        Arguments -&gt; the portfolio and claims dataframes, the features for which we will impute a value for the identified policies,   
            (since the policies are added in the porfolio, a value has to be assumed for each of their features)   
            the policy id column name to use and the policy id name we will give to these policies found in the claims but not in the porfolio   
        Returns --&gt; a new portfolio and claims dataframe with the new policy name given to the identified policies  
    &#34;&#34;&#34;

    new_df_portfolio, new_df_claims = deepcopy(df_portfolio), deepcopy(df_claims)

    # Finds the claimants that do not exist in the portfolio data
    mask = ~new_df_claims[policy_id_column_name].isin(new_df_portfolio[policy_id_column_name])
    df_not_existing_policies = new_df_claims[mask]

    new_df_claims.loc[df_not_existing_policies.index, policy_id_column_name] = unknown_row_name

    # Reseting df index just in case to be sure we take the last row using shape
    new_df_portfolio = new_df_portfolio.reset_index(drop=True)
    # Gets the last row values and affect them to a new row
    new_row_df = new_df_portfolio.loc[new_df_portfolio.shape[0]-1]
    new_df_portfolio.loc[new_df_portfolio.shape[0]] = new_row_df
    new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, [policy_id_column_name]] = unknown_row_name

    # For each feature, derives the mode or the average and assigns it to the new row (a simple fillna might be faster)
    for feature in features_analysis:
        if new_df_portfolio[feature].dtype in [&#39;object&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mode()[0]
        elif new_df_portfolio[feature].dtype in [&#39;float64&#39;, &#39;int64&#39;, &#39;int32&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mean()

    print(&#39;There are {} policies in the claims that cannot be found in the porfolio data&#39;.format(df_not_existing_policies.shape[0]))

    return new_df_portfolio, new_df_claims</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.find_outliers"><code class="name flex">
<span>def <span class="ident">find_outliers</span></span>(<span>df, columns=None, method='interquartile', z_score_threshold=3, interquartile_lower_bound=0.25, interquartile_upper_bound=0.75)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds outliers for the specified features <br>
Arguments &ndash;&gt; the dataframe on which to find outliers, the features as a name or list of names and the method to use to find outliers (either interquartile or z-score) <br>
the z-score and the interquartile thresholds to use <br>
Returns &ndash;&gt; the initial dataframe, the dataframe with only outliers and the new df without the outliers</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_outliers(df, columns=None, method=&#39;interquartile&#39;, z_score_threshold=3, interquartile_lower_bound=0.25, interquartile_upper_bound=0.75):
    &#34;&#34;&#34;
        Finds outliers for the specified features   
        Arguments --&gt; the dataframe on which to find outliers, the features as a name or list of names and the method to use to find outliers (either interquartile or z-score)   
            the z-score and the interquartile thresholds to use   
        Returns --&gt; the initial dataframe, the dataframe with only outliers and the new df without the outliers
    &#34;&#34;&#34;

    new_df = deepcopy(df)

    if method == &#39;interquartile&#39;:
        new_columns = [columns] if isinstance(columns, str) == True else columns

        for column in new_columns:
            quantile_25 = df[column].quantile(interquartile_lower_bound)
            quantile_75 = df[column].quantile(interquartile_upper_bound)

            interquartile_range = quantile_75 - quantile_25
            lower_bound = quantile_25 - 1.5 * interquartile_range
            upper_bound = quantile_75 + 1.5 * interquartile_range

            new_df = new_df[(new_df[column] &gt;= lower_bound) &amp; (new_df[column] &lt;= upper_bound)]

    else:

        z_score = np.abs(stats.zscore(df[columns]))
        new_df = new_df[z_score&lt;3] if isinstance(columns, str) == True else new_df[(z_score&lt;3).all(axis=1)]

    df_outliers = df[~df.index.isin(new_df.index)]
    proportion_outliers = len(df_outliers) / len(df)

    if proportion_outliers &gt; 0.05:
        print(&#34;Outliers represent a high proportion of the data: {}%. We should not remove them all&#34;.format(proportion_outliers))
        return deepcopy(df), df_outliers, df
    else:
        print(&#39;{} rows have been removed&#39;.format(df_outliers.shape[0]))
        return deepcopy(df), df_outliers, new_df</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.find_wrong_lines"><code class="name flex">
<span>def <span class="ident">find_wrong_lines</span></span>(<span>df, main_column_contract_date, lines_ro_remove_name, number_of_days=None, remove=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the lines that seem to be wrong either because they are duplicates or because a date inconsistency has been detected <br>
Arguments &ndash;&gt; the df on which we are doing the check, the constract start date columns, <br>
the name that will be given to the rows flagged as wrong, the number of days that should serve to check dates consistency (usually 365 for yearly contracts) <br>
i.e. for a given policy and its effective date, a claim occurring beyond that number of days should not be associate to it (usually 365 for yearly contracts), <br>
and a remove argument that if set to True means all the lines considered wrong are removed from the df <br>
Returns &ndash;&gt; 2 dataframes, one which will be either with a flag for wrong lines or with all these lines removed, <br>
and a new one which contains only the removed lines</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_wrong_lines(df, main_column_contract_date, lines_ro_remove_name, number_of_days=None, remove=False):
    &#34;&#34;&#34;
        Finds the lines that seem to be wrong either because they are duplicates or because a date inconsistency has been detected   
        Arguments --&gt; the df on which we are doing the check, the constract start date columns,   
            the name that will be given to the rows flagged as wrong, the number of days that should serve to check dates consistency (usually 365 for yearly contracts)   
            i.e. for a given policy and its effective date, a claim occurring beyond that number of days should not be associate to it (usually 365 for yearly contracts),   
            and a remove argument that if set to True means all the lines considered wrong are removed from the df   
        Returns --&gt; 2 dataframes, one which will be either with a flag for wrong lines or with all these lines removed,   
                    and a new one which contains only the removed lines
    &#34;&#34;&#34;

    new_df = deepcopy(df)
    number_of_days = 365 if number_of_days is None else number_of_days

    new_df[lines_ro_remove_name] = new_df.index.to_frame()[0].apply(lambda x: check_row_consistency(x, new_df, main_column_contract_date, number_of_days))

    if remove == True:
        df_removed_lines = new_df[new_df[lines_ro_remove_name] == 1]
        line_to_remove_index = df_removed_lines.index
        new_df = new_df.drop(labels=line_to_remove_index).drop(columns=lines_ro_remove_name)
    else:
        df_removed_lines = pd.DataFrame()
        print(&#39;You just agged the lines that are incorrect and should most likely be removed.  \n \
Retreat these lines, then run again this function with the remove argument set to True to delete remaining unnecessary lines&#39;)

    return new_df.reset_index(drop=True), df_removed_lines</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.perform_sense_check"><code class="name flex">
<span>def <span class="ident">perform_sense_check</span></span>(<span>df, new_cell_name=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds data which is inconsistent on the columns specified in the kwargs <br>
Arguments &ndash;&gt; the dataframe, the name of the new column created to flag if the row is consistent or not, <br>
if not specified, then the function creates a new df composed of the rows for which the comparison check is true <br>
kwargs &ndash;&gt; tuples like (column1, column2, comparison_to_do, strict_comparison) <br>
or (column1, integer, comparison_to_do) ; comparison_to_do must be 0 for ==, 1 for &lt;=, 2 for &gt;= <br>
if strict_comparison is True, then the comparison must be strict (&gt; or &lt;) <br>
Returns &ndash;&gt; either a new dataframe containing all rows that meet the comparison check or the current dataframe with a new cell that flags them</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def perform_sense_check(df, new_cell_name=None, **kwargs):
    &#34;&#34;&#34;
       Finds data which is inconsistent on the columns specified in the kwargs   
       Arguments --&gt; the dataframe, the name of the new column created to flag if the row is consistent or not,   
            if not specified, then the function creates a new df composed of the rows for which the comparison check is true   
            kwargs --&gt; tuples like (column1, column2, comparison_to_do, strict_comparison)   
            or (column1, integer, comparison_to_do) ; comparison_to_do must be 0 for ==, 1 for &lt;=, 2 for &gt;=   
            if strict_comparison is True, then the comparison must be strict (&gt; or &lt;)   
       Returns --&gt; either a new dataframe containing all rows that meet the comparison check or the current dataframe with a new cell that flags them
   &#34;&#34;&#34;

    # Defines if the second argument to compare with is a integer/float or a pandas serie   
    # Returns --&gt; the right element that must be used for the comparison
    def get_compare():

        if isinstance(value[1], str) == True:
            # The second element of the tuple being a column name, we get the pandas serie
            compare = df[value[1]]            
        else:
            # The second element of the tuple being a number, we just retrieve the number itself
            compare = value[1]
            

        return compare

    #Returns the concatenated dataframe validating the check or updates the df column used to flag if the comparison is true or not
    def create_new_cell_or_df(): 

        # Cell name not being defined, it means the function must create a dataframe
        if new_cell_name is None:
            # As several checks can be done, a concatenation between the previous check and the new one is made
            return pd.concat((df_check, df[mask]), axis=0).drop_duplicates(keep=&#39;first&#39;)
        else:
            # The original df is modified with a new column that will have true/false value. If there are several checks performed, the row will be flagged true if it validates at least 1 check
            df[new_cell_name] = df[new_cell_name] | mask if new_cell_name in df.columns else mask

         
    df_check = pd.DataFrame()
    
    # Loops trough the kwargs
    for value in kwargs.values():

        # These lines checks the comparison operation to do
        if value[2] == 0:
            compare = get_compare()           
            mask = df[value[0]] == compare

        elif value[2] == 1:
            compare = get_compare()
            mask = df[value[0]] &lt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &lt; compare
            
        else:
            compare = get_compare()
            mask = df[value[0]] &gt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &gt; compare
        
        df_check = create_new_cell_or_df()
            
    if new_cell_name is None:
        print(&#39;There are {} rows concerned&#39;.format(df_check.shape[0]))
        return df_check</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="automate_insurance_pricing.exploration" href="index.html">automate_insurance_pricing.exploration</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.add_back_lines" href="#automate_insurance_pricing.exploration.checks_functions.add_back_lines">add_back_lines</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.check_row_consistency" href="#automate_insurance_pricing.exploration.checks_functions.check_row_consistency">check_row_consistency</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.create_unknown_policy" href="#automate_insurance_pricing.exploration.checks_functions.create_unknown_policy">create_unknown_policy</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.find_outliers" href="#automate_insurance_pricing.exploration.checks_functions.find_outliers">find_outliers</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.find_wrong_lines" href="#automate_insurance_pricing.exploration.checks_functions.find_wrong_lines">find_wrong_lines</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.perform_sense_check" href="#automate_insurance_pricing.exploration.checks_functions.perform_sense_check">perform_sense_check</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>