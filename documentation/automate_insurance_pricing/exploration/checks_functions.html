<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>automate_insurance_pricing.exploration.checks_functions API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>automate_insurance_pricing.exploration.checks_functions</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np

from scipy import stats

from copy import deepcopy
from datetime import date, timedelta, datetime



def update_costs_for_year(x, df, policy_id_column_name, main_column_contract_date, claim_occurrence_date, unknown_row_name, number_of_days):
    &#34;&#34;&#34;Checks if the line should be in the df or if it is a wrong or true duplicate that should be removed&#34;&#34;&#34;

    row = df.loc[x]
    policy_id = row[policy_id_column_name]
    year_name = main_column_contract_date
    result = 0
    effective_date = row[year_name]
    effective_dates = df[df[policy_id_column_name]==policy_id][year_name]

    # For policy_id with UNKNOWN value, we keep all claims because we cannot link them to a policy but we group them in an UNKNOWN block so that we don&#39;t understimate the total cost
    if policy_id != unknown_row_name:
        # Contract started after the claim occurrence
        if effective_date &gt; row[claim_occurrence_date]:
            result = 1
        # The claim did not occurr during the yearly contract cover;
        # By prudency, also checks if there is a contract amendment. if not we assume it is a date mistake and we do not set the cost to 0
        elif effective_date + timedelta(number_of_days) &lt;= row[claim_occurrence_date] and effective_date &lt; effective_dates.max():
            result = 1

    return result


def add_back_lines(df, df_removed, main_column_contract_date, claim_id_column_name, claim_occurrence_date_column_name, lines_ro_remove_name):
    &#34;&#34;&#34;
        Add backs lines that were mistakenly removed from the df
        Arguments --&gt; the reduced df and the df that stores the removed lines
        Returns --&gt; a new df which now have back the lines that were wrongly removed
    &#34;&#34;&#34;

    year_name = main_column_contract_date

    # To find these claims we look at the claims that were in the original claims data but are not in the newly created
    wrongly_removed = df_removed[~df_removed[claim_id_column_name].isin(df[claim_id_column_name])].drop_duplicates(subset=claim_id_column_name, keep=&#39;last&#39;)

    # We add them back in our claims because we prefer being wrong in the occurrence dates rather than reducing the total costs
    new_df = pd.concat((df, wrongly_removed), sort=False).reset_index(drop=True)

    # Changes the dates so that it is now consistent. It means there might be cost overestimation for some occurrence year, but it won&#39;t have any impact overall
    new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, claim_occurrence_date_column_name] = new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, year_name] + timedelta(days=1)

    return new_df.drop(columns=lines_ro_remove_name, errors=&#39;ignore&#39;)



def find_wrong_lines(df, main_column_contract_date, lines_ro_remove_name, number_of_days=None, remove=False):
    &#34;&#34;&#34;
        Finds the lines that seems to be wrong either because they are true duplicates or because a date inconsistency has been detected
        Arguments --&gt; the df on which we are doing the check, the number of days that should serve as a threshold \n \
                    i.e. for a given policy and its effective date, a claim occurring beyond that number of days should not be associate to it,
                    and a remove argument that if set to True means all the lines considered wrong are removed from the df
        Returns --&gt; 2 df, one which is either with a flat for potential wrong lines or with all these lines removed, \n \
and a new one which contains only the removed lines
    &#34;&#34;&#34;

    new_df = deepcopy(df)
    number_of_days = 365 if number_of_days is None else number_of_days

    new_df[lines_ro_remove_name] = new_df.index.to_frame()[0].apply(lambda x: update_costs_for_year(x, new_df, main_column_contract_date, number_of_days))

    if remove == True:
        df_removed_lines = new_df[new_df[lines_ro_remove_name] == 1]
        line_to_remove_index = df_removed_lines.index
        new_df = new_df.drop(labels=line_to_remove_index).drop(columns=lines_ro_remove_name)
    else:
        df_removed_lines = pd.DataFrame()
        print(&#39;You just tagged the lines that are incorrect and should most likely be removed.\n \
Retreat these lines, then run again this function with the remove argument set to True to delete remaining unnecessary lines&#39;)

    return new_df.reset_index(drop=True), df_removed_lines



def create_unknown_policy(df_portfolio, df_claims, features_analysis, policy_id_column_name=&#39;policy_id&#39;, unknown_row_name=&#39;UNKNOWN&#39;):
    &#34;&#34;&#34; Finds policies that are in the claims data but not in the porfolio, and generates a new policy on the portfolio data to represent these unknown policies&#34;&#34;&#34;

    new_df_portfolio, new_df_claims = deepcopy(df_portfolio), deepcopy(df_claims)

    # Finds the claimants that do not exist in the portfolio data
    mask = ~new_df_claims[policy_id_column_name].isin(new_df_portfolio[policy_id_column_name])
    df_not_existing_policies = new_df_claims[mask]

    new_df_claims.loc[df_not_existing_policies.index, policy_id_column_name] = unknown_row_name

    # Reseting df index just in case to be sure we take the last row using shape
    new_df_portfolio = new_df_portfolio.reset_index(drop=True)
    # Gets the last row values and affect them to a new row
    new_row_df = new_df_portfolio.loc[new_df_portfolio.shape[0]-1]
    new_df_portfolio.loc[new_df_portfolio.shape[0]] = new_row_df
    new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, [policy_id_column_name]] = unknown_row_name

    # For each feature, derives the mode or the average and assigns it to the new row (a simple fillna might be faster)
    for feature in features_analysis:
        if new_df_portfolio[feature].dtype in [&#39;object&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mode()[0]
        elif new_df_portfolio[feature].dtype in [&#39;float64&#39;, &#39;int64&#39;, &#39;int32&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mean()

    print(&#39;There are {} policies in the claims that cannot be found in the porfolio data&#39;.format(df_not_existing_policies.shape[0]))

    return new_df_portfolio, new_df_claims



def find_outliers(df, columns=None, method=&#39;interquartile&#39;, z_score_threshold=3, interquartile_lower_bound=0.25, interquartile_upper_bound=0.75):
    &#34;&#34;&#34;
        Finds outliers for the specified features
        Arguments --&gt; the df on which to find outliers, the features as a name or list of names and the method to use to find outliers
        Returns --&gt; a full copy of df, the df with only outliers and the new df without the outliers
    &#34;&#34;&#34;

    new_df = deepcopy(df)

    if method == &#39;interquartile&#39;:
        new_columns = [columns] if isinstance(columns, str) == True else columns

        for column in new_columns:
            quantile_25 = df[column].quantile(interquartile_lower_bound)
            quantile_75 = df[column].quantile(interquartile_upper_bound)

            interquartile_range = quantile_75 - quantile_25
            lower_bound = quantile_25 - 1.5 * interquartile_range
            upper_bound = quantile_75 + 1.5 * interquartile_range

            new_df = new_df[(new_df[column] &gt;= lower_bound) &amp; (new_df[column] &lt;= upper_bound)]

    else:

        z_score = np.abs(stats.zscore(df[columns]))
        new_df = new_df[z_score&lt;3] if isinstance(columns, str) == True else new_df[(z_score&lt;3).all(axis=1)]

    df_outliers = df[~df.index.isin(new_df.index)]
    proportion_outliers = len(df_outliers) / len(df)

    if proportion_outliers &gt; 0.05:
        print(&#34;Outliers represent a high proportion of the data: {}%. We should not remove them all&#34;.format(proportion_outliers))
        return deepcopy(df), df_outliers, df
    else:
        print(&#39;{} rows have been removed&#39;.format(df_outliers.shape[0]))
        return deepcopy(df), df_outliers, new_df
    
    

def perform_sense_check(df, new_cell_name=None, **kwargs):
    &#34;&#34;&#34;
       Finds data which is inconsistent on the columns specified in the kwargs
       Arguments --&gt; the df, the name of the new column created to flag if the comparison is true or not,
                if not specified, then the function creates a new df composed of the rows for which the comparison check is true
                   kwargs --&gt; tuples like (column1, column2, comparison_to_do, strict_comparison)
                   or (column1, integer, comparison_to_do) ; comparison_to_do must be 0 for ==, 1 for &lt;=, 2 for &gt;=
                    if strict_comparison is True, then the comparison must be strict
       Returns --&gt; either a new df containing all rows that meet the comparison check or the current df with a new cell that flags them
   &#34;&#34;&#34;

    def get_compare():
        &#34;&#34;&#34;
            Defines if the second argument to compare with is a integer/float or a pandas serie
            Returns --&gt; the right element that must be used for the comparison
        &#34;&#34;&#34;

        if isinstance(value[1], str) == True:
            # The second element of the tuple being a column name, we get the pandas serie
            compare = df[value[1]]            
        else:
            # The second element of the tuple being a number, we just retrieve the number itself
            compare = value[1]
            

        return compare


    def create_new_cell_or_df(): 
        &#34;&#34;&#34; Returns the concatenated df validating the check or updates the df column used to flag if the comparison is true or not&#34;&#34;&#34;

        # Cell name not being defined, it means the function must create a dataframe
        if new_cell_name is None:
            # As several checks can be done, a concatenation between the previous check and the new one is made
            return pd.concat((df_check, df[mask]), axis=0).drop_duplicates(keep=&#39;first&#39;)
        else:
            # The original df is modified with a new column that will have true/false value. If there are several checks performed, the row will be flagged true if it validates at least 1 check
            df[new_cell_name] = df[new_cell_name] | mask if new_cell_name in df.columns else mask

         
    df_check = pd.DataFrame()
    
    # Loops trough the kwargs
    for value in kwargs.values():

        # These lines checks the comparison operation to do
        if value[2] == 0:
            compare = get_compare()           
            mask = df[value[0]] == compare

        elif value[2] == 1:
            compare = get_compare()
            mask = df[value[0]] &lt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &lt; compare
            
        else:
            compare = get_compare()
            mask = df[value[0]] &gt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &gt; compare
        
        df_check = create_new_cell_or_df()
            
    if new_cell_name is None:
        print(&#39;There are {} rows concerned&#39;.format(df_check.shape[0]))
        return df_check
      


def build_duplicated_df(df, columns=None, keep_method=False):
    &#34;&#34;&#34; Finds the duplicated values depending on the args
        columns --&gt; columns names specified by the user as a list. Can be just a string if it is for only one column
        Returns --&gt; a new dataframe with only duplicated values
    &#34;&#34;&#34;

    return df[df.duplicated(subset=columns, keep=keep_method)].sort_values(columns)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="automate_insurance_pricing.exploration.checks_functions.add_back_lines"><code class="name flex">
<span>def <span class="ident">add_back_lines</span></span>(<span>df, df_removed, main_column_contract_date, claim_id_column_name, claim_occurrence_date_column_name, lines_ro_remove_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Add backs lines that were mistakenly removed from the df
Arguments &ndash;&gt; the reduced df and the df that stores the removed lines
Returns &ndash;&gt; a new df which now have back the lines that were wrongly removed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_back_lines(df, df_removed, main_column_contract_date, claim_id_column_name, claim_occurrence_date_column_name, lines_ro_remove_name):
    &#34;&#34;&#34;
        Add backs lines that were mistakenly removed from the df
        Arguments --&gt; the reduced df and the df that stores the removed lines
        Returns --&gt; a new df which now have back the lines that were wrongly removed
    &#34;&#34;&#34;

    year_name = main_column_contract_date

    # To find these claims we look at the claims that were in the original claims data but are not in the newly created
    wrongly_removed = df_removed[~df_removed[claim_id_column_name].isin(df[claim_id_column_name])].drop_duplicates(subset=claim_id_column_name, keep=&#39;last&#39;)

    # We add them back in our claims because we prefer being wrong in the occurrence dates rather than reducing the total costs
    new_df = pd.concat((df, wrongly_removed), sort=False).reset_index(drop=True)

    # Changes the dates so that it is now consistent. It means there might be cost overestimation for some occurrence year, but it won&#39;t have any impact overall
    new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, claim_occurrence_date_column_name] = new_df.loc[new_df.shape[0]-wrongly_removed.shape[0]:, year_name] + timedelta(days=1)

    return new_df.drop(columns=lines_ro_remove_name, errors=&#39;ignore&#39;)</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.build_duplicated_df"><code class="name flex">
<span>def <span class="ident">build_duplicated_df</span></span>(<span>df, columns=None, keep_method=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the duplicated values depending on the args
columns &ndash;&gt; columns names specified by the user as a list. Can be just a string if it is for only one column
Returns &ndash;&gt; a new dataframe with only duplicated values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_duplicated_df(df, columns=None, keep_method=False):
    &#34;&#34;&#34; Finds the duplicated values depending on the args
        columns --&gt; columns names specified by the user as a list. Can be just a string if it is for only one column
        Returns --&gt; a new dataframe with only duplicated values
    &#34;&#34;&#34;

    return df[df.duplicated(subset=columns, keep=keep_method)].sort_values(columns)</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.create_unknown_policy"><code class="name flex">
<span>def <span class="ident">create_unknown_policy</span></span>(<span>df_portfolio, df_claims, features_analysis, policy_id_column_name='policy_id', unknown_row_name='UNKNOWN')</span>
</code></dt>
<dd>
<div class="desc"><p>Finds policies that are in the claims data but not in the porfolio, and generates a new policy on the portfolio data to represent these unknown policies</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_unknown_policy(df_portfolio, df_claims, features_analysis, policy_id_column_name=&#39;policy_id&#39;, unknown_row_name=&#39;UNKNOWN&#39;):
    &#34;&#34;&#34; Finds policies that are in the claims data but not in the porfolio, and generates a new policy on the portfolio data to represent these unknown policies&#34;&#34;&#34;

    new_df_portfolio, new_df_claims = deepcopy(df_portfolio), deepcopy(df_claims)

    # Finds the claimants that do not exist in the portfolio data
    mask = ~new_df_claims[policy_id_column_name].isin(new_df_portfolio[policy_id_column_name])
    df_not_existing_policies = new_df_claims[mask]

    new_df_claims.loc[df_not_existing_policies.index, policy_id_column_name] = unknown_row_name

    # Reseting df index just in case to be sure we take the last row using shape
    new_df_portfolio = new_df_portfolio.reset_index(drop=True)
    # Gets the last row values and affect them to a new row
    new_row_df = new_df_portfolio.loc[new_df_portfolio.shape[0]-1]
    new_df_portfolio.loc[new_df_portfolio.shape[0]] = new_row_df
    new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, [policy_id_column_name]] = unknown_row_name

    # For each feature, derives the mode or the average and assigns it to the new row (a simple fillna might be faster)
    for feature in features_analysis:
        if new_df_portfolio[feature].dtype in [&#39;object&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mode()[0]
        elif new_df_portfolio[feature].dtype in [&#39;float64&#39;, &#39;int64&#39;, &#39;int32&#39;]:
            new_df_portfolio.loc[new_df_portfolio.shape[0]-1:, feature] = new_df_portfolio[feature].mean()

    print(&#39;There are {} policies in the claims that cannot be found in the porfolio data&#39;.format(df_not_existing_policies.shape[0]))

    return new_df_portfolio, new_df_claims</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.find_outliers"><code class="name flex">
<span>def <span class="ident">find_outliers</span></span>(<span>df, columns=None, method='interquartile', z_score_threshold=3, interquartile_lower_bound=0.25, interquartile_upper_bound=0.75)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds outliers for the specified features
Arguments &ndash;&gt; the df on which to find outliers, the features as a name or list of names and the method to use to find outliers
Returns &ndash;&gt; a full copy of df, the df with only outliers and the new df without the outliers</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_outliers(df, columns=None, method=&#39;interquartile&#39;, z_score_threshold=3, interquartile_lower_bound=0.25, interquartile_upper_bound=0.75):
    &#34;&#34;&#34;
        Finds outliers for the specified features
        Arguments --&gt; the df on which to find outliers, the features as a name or list of names and the method to use to find outliers
        Returns --&gt; a full copy of df, the df with only outliers and the new df without the outliers
    &#34;&#34;&#34;

    new_df = deepcopy(df)

    if method == &#39;interquartile&#39;:
        new_columns = [columns] if isinstance(columns, str) == True else columns

        for column in new_columns:
            quantile_25 = df[column].quantile(interquartile_lower_bound)
            quantile_75 = df[column].quantile(interquartile_upper_bound)

            interquartile_range = quantile_75 - quantile_25
            lower_bound = quantile_25 - 1.5 * interquartile_range
            upper_bound = quantile_75 + 1.5 * interquartile_range

            new_df = new_df[(new_df[column] &gt;= lower_bound) &amp; (new_df[column] &lt;= upper_bound)]

    else:

        z_score = np.abs(stats.zscore(df[columns]))
        new_df = new_df[z_score&lt;3] if isinstance(columns, str) == True else new_df[(z_score&lt;3).all(axis=1)]

    df_outliers = df[~df.index.isin(new_df.index)]
    proportion_outliers = len(df_outliers) / len(df)

    if proportion_outliers &gt; 0.05:
        print(&#34;Outliers represent a high proportion of the data: {}%. We should not remove them all&#34;.format(proportion_outliers))
        return deepcopy(df), df_outliers, df
    else:
        print(&#39;{} rows have been removed&#39;.format(df_outliers.shape[0]))
        return deepcopy(df), df_outliers, new_df</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.find_wrong_lines"><code class="name flex">
<span>def <span class="ident">find_wrong_lines</span></span>(<span>df, main_column_contract_date, lines_ro_remove_name, number_of_days=None, remove=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the lines that seems to be wrong either because they are true duplicates or because a date inconsistency has been detected
Arguments &ndash;&gt; the df on which we are doing the check, the number of days that should serve as a threshold
i.e. for a given policy and its effective date, a claim occurring beyond that number of days should not be associate to it,
and a remove argument that if set to True means all the lines considered wrong are removed from the df
Returns &ndash;&gt; 2 df, one which is either with a flat for potential wrong lines or with all these lines removed,
and a new one which contains only the removed lines</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_wrong_lines(df, main_column_contract_date, lines_ro_remove_name, number_of_days=None, remove=False):
    &#34;&#34;&#34;
        Finds the lines that seems to be wrong either because they are true duplicates or because a date inconsistency has been detected
        Arguments --&gt; the df on which we are doing the check, the number of days that should serve as a threshold \n \
                    i.e. for a given policy and its effective date, a claim occurring beyond that number of days should not be associate to it,
                    and a remove argument that if set to True means all the lines considered wrong are removed from the df
        Returns --&gt; 2 df, one which is either with a flat for potential wrong lines or with all these lines removed, \n \
and a new one which contains only the removed lines
    &#34;&#34;&#34;

    new_df = deepcopy(df)
    number_of_days = 365 if number_of_days is None else number_of_days

    new_df[lines_ro_remove_name] = new_df.index.to_frame()[0].apply(lambda x: update_costs_for_year(x, new_df, main_column_contract_date, number_of_days))

    if remove == True:
        df_removed_lines = new_df[new_df[lines_ro_remove_name] == 1]
        line_to_remove_index = df_removed_lines.index
        new_df = new_df.drop(labels=line_to_remove_index).drop(columns=lines_ro_remove_name)
    else:
        df_removed_lines = pd.DataFrame()
        print(&#39;You just tagged the lines that are incorrect and should most likely be removed.\n \
Retreat these lines, then run again this function with the remove argument set to True to delete remaining unnecessary lines&#39;)

    return new_df.reset_index(drop=True), df_removed_lines</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.perform_sense_check"><code class="name flex">
<span>def <span class="ident">perform_sense_check</span></span>(<span>df, new_cell_name=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds data which is inconsistent on the columns specified in the kwargs
Arguments &ndash;&gt; the df, the name of the new column created to flag if the comparison is true or not,
if not specified, then the function creates a new df composed of the rows for which the comparison check is true
kwargs &ndash;&gt; tuples like (column1, column2, comparison_to_do, strict_comparison)
or (column1, integer, comparison_to_do) ; comparison_to_do must be 0 for ==, 1 for &lt;=, 2 for &gt;=
if strict_comparison is True, then the comparison must be strict
Returns &ndash;&gt; either a new df containing all rows that meet the comparison check or the current df with a new cell that flags them</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def perform_sense_check(df, new_cell_name=None, **kwargs):
    &#34;&#34;&#34;
       Finds data which is inconsistent on the columns specified in the kwargs
       Arguments --&gt; the df, the name of the new column created to flag if the comparison is true or not,
                if not specified, then the function creates a new df composed of the rows for which the comparison check is true
                   kwargs --&gt; tuples like (column1, column2, comparison_to_do, strict_comparison)
                   or (column1, integer, comparison_to_do) ; comparison_to_do must be 0 for ==, 1 for &lt;=, 2 for &gt;=
                    if strict_comparison is True, then the comparison must be strict
       Returns --&gt; either a new df containing all rows that meet the comparison check or the current df with a new cell that flags them
   &#34;&#34;&#34;

    def get_compare():
        &#34;&#34;&#34;
            Defines if the second argument to compare with is a integer/float or a pandas serie
            Returns --&gt; the right element that must be used for the comparison
        &#34;&#34;&#34;

        if isinstance(value[1], str) == True:
            # The second element of the tuple being a column name, we get the pandas serie
            compare = df[value[1]]            
        else:
            # The second element of the tuple being a number, we just retrieve the number itself
            compare = value[1]
            

        return compare


    def create_new_cell_or_df(): 
        &#34;&#34;&#34; Returns the concatenated df validating the check or updates the df column used to flag if the comparison is true or not&#34;&#34;&#34;

        # Cell name not being defined, it means the function must create a dataframe
        if new_cell_name is None:
            # As several checks can be done, a concatenation between the previous check and the new one is made
            return pd.concat((df_check, df[mask]), axis=0).drop_duplicates(keep=&#39;first&#39;)
        else:
            # The original df is modified with a new column that will have true/false value. If there are several checks performed, the row will be flagged true if it validates at least 1 check
            df[new_cell_name] = df[new_cell_name] | mask if new_cell_name in df.columns else mask

         
    df_check = pd.DataFrame()
    
    # Loops trough the kwargs
    for value in kwargs.values():

        # These lines checks the comparison operation to do
        if value[2] == 0:
            compare = get_compare()           
            mask = df[value[0]] == compare

        elif value[2] == 1:
            compare = get_compare()
            mask = df[value[0]] &lt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &lt; compare
            
        else:
            compare = get_compare()
            mask = df[value[0]] &gt;= compare if len(value) &lt; 4 or value[3] == False else df[value[0]] &gt; compare
        
        df_check = create_new_cell_or_df()
            
    if new_cell_name is None:
        print(&#39;There are {} rows concerned&#39;.format(df_check.shape[0]))
        return df_check</code></pre>
</details>
</dd>
<dt id="automate_insurance_pricing.exploration.checks_functions.update_costs_for_year"><code class="name flex">
<span>def <span class="ident">update_costs_for_year</span></span>(<span>x, df, policy_id_column_name, main_column_contract_date, claim_occurrence_date, unknown_row_name, number_of_days)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if the line should be in the df or if it is a wrong or true duplicate that should be removed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_costs_for_year(x, df, policy_id_column_name, main_column_contract_date, claim_occurrence_date, unknown_row_name, number_of_days):
    &#34;&#34;&#34;Checks if the line should be in the df or if it is a wrong or true duplicate that should be removed&#34;&#34;&#34;

    row = df.loc[x]
    policy_id = row[policy_id_column_name]
    year_name = main_column_contract_date
    result = 0
    effective_date = row[year_name]
    effective_dates = df[df[policy_id_column_name]==policy_id][year_name]

    # For policy_id with UNKNOWN value, we keep all claims because we cannot link them to a policy but we group them in an UNKNOWN block so that we don&#39;t understimate the total cost
    if policy_id != unknown_row_name:
        # Contract started after the claim occurrence
        if effective_date &gt; row[claim_occurrence_date]:
            result = 1
        # The claim did not occurr during the yearly contract cover;
        # By prudency, also checks if there is a contract amendment. if not we assume it is a date mistake and we do not set the cost to 0
        elif effective_date + timedelta(number_of_days) &lt;= row[claim_occurrence_date] and effective_date &lt; effective_dates.max():
            result = 1

    return result</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="automate_insurance_pricing.exploration" href="index.html">automate_insurance_pricing.exploration</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.add_back_lines" href="#automate_insurance_pricing.exploration.checks_functions.add_back_lines">add_back_lines</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.build_duplicated_df" href="#automate_insurance_pricing.exploration.checks_functions.build_duplicated_df">build_duplicated_df</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.create_unknown_policy" href="#automate_insurance_pricing.exploration.checks_functions.create_unknown_policy">create_unknown_policy</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.find_outliers" href="#automate_insurance_pricing.exploration.checks_functions.find_outliers">find_outliers</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.find_wrong_lines" href="#automate_insurance_pricing.exploration.checks_functions.find_wrong_lines">find_wrong_lines</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.perform_sense_check" href="#automate_insurance_pricing.exploration.checks_functions.perform_sense_check">perform_sense_check</a></code></li>
<li><code><a title="automate_insurance_pricing.exploration.checks_functions.update_costs_for_year" href="#automate_insurance_pricing.exploration.checks_functions.update_costs_for_year">update_costs_for_year</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>